#include "SBNcovar.h"
//#include "MCEventWeight.h"

using namespace sbn;



SBNcovar::SBNcovar(std::string xmlname) : SBNconfig(xmlname) {
	std::string dict_location = "../../src/AutoDict_map_string__vector_double____cxx.so";
	gROOT->ProcessLine("#include <map>");
	gROOT->ProcessLine("#include <vector>");
	gROOT->ProcessLine("#include <string>");
	//	gSystem->Load("/uboone/app/users/markrl/sbnfit/whipping_star/src/mdict_h.so");

	std::cout<<"Trying to load dictionary: "<<dict_location<<std::endl;
	gSystem->Load(  (dict_location).c_str());
	gStyle->SetOptStat(0);


	universes_used = 0;
	tolerence_positivesemi = 1e-5;
	is_small_negative_eigenvalue = false;
	bool DEBUG_BOOL = false;
	std::map<std::string, int> parameter_sims;


	//Initilise one SBNspec to use as a template, as per XMl instructions
	template_spec =SBNspec(xmlname,-1);
	spec_CV = template_spec;


	//Get files all set up and loaded
	Nfiles = multisim_file.size();

	for(auto &fn: multisim_file){
		files.push_back(new TFile(fn.c_str()));
	}

	for(int i=0; i<multisim_name.size(); i++){
		trees.push_back((TTree*)files.at(i)->Get(multisim_name[i].c_str()) );
	}

	for(auto &t: trees){
		nentries.push_back(50);
		//nentries.push_back(t->GetEntries());
	}


	//List of variables, both int and double
	vars_i= std::vector<std::vector<int>>(Nfiles   , std::vector<int>(branch_names_int.at(0).size(),0));
	vars_d= std::vector<std::vector<double>>(Nfiles   , std::vector<double>(branch_names_double.at(0).size(),0.0));


	bWeights.resize(Nfiles,0);
	bLepMom.resize(Nfiles,0);

	fWeights.resize(multisim_name.size(),0);
	fLepMom.resize(Nfiles,0);


	//For each file set the weight, lepmom and int/double from xml file	
	for(int i=0; i< Nfiles; i++){
		trees.at(i)->SetBranchAddress("mcweight", &(fWeights.at(i)), &(bWeights.at(i)) );
		trees.at(i)->SetBranchAddress("leptonMom", &(fLepMom.at(i)), &(bLepMom.at(i))  );

		for(auto &bfni: branch_names_int){
			for(int k=0; k< bfni.size();k++){
				trees.at(i)->SetBranchAddress(bfni[k].c_str(), &(vars_i.at(i).at(k)));
			}
		}
		for(auto &bfnd: branch_names_double){
			for(int k=0; k< bfnd.size();k++){
				trees.at(i)->SetBranchAddress(bfnd[k].c_str(), &(vars_d.at(i).at(k)));
			}
		}
	}


	//Setting up storage 
	full_covariance.ResizeTo(num_bins_total, num_bins_total);
	frac_covariance.ResizeTo(num_bins_total, num_bins_total);
	full_correlation.ResizeTo(num_bins_total, num_bins_total);

	//prepare three TH2D for plotting 
	hist_frac_cov = new TH2D("Frac Cov","",num_bins_total,1,num_bins_total, num_bins_total,1,num_bins_total);
	hist_full_cor = new TH2D("Corr","",num_bins_total,1,num_bins_total, num_bins_total,1,num_bins_total);
	hist_full_cov = new TH2D("Full Cov","",num_bins_total,1,num_bins_total, num_bins_total,1,num_bins_total);

	//This bit will calculate how many "multisims" the file has. if ALL default is the inputted xml value 
	// use a known good event (2 has been checked)
	int good_event = 2;
	if(parameter_names.at(0)[0]!="ALL"){
		std::vector<int> used_multisims;

		for(int j=0; j< Nfiles; j++){
			trees.at(j)->GetEntry(good_event);
			std::vector<double> num_sim_here = fWeights.at(j)->at(parameter_names.at(j)[0]);
			std::cout<<"File: "<<j<<" has: "<<num_sim_here.size()<<" universes for parameter: "<<parameter_names.at(j)[0]<<std::endl; 
			used_multisims.push_back(num_sim_here.size());
		}

		for(int i=1; i<Nfiles; i++){
			std::cout<<"File: "<<i-1<<" has "<<used_multisims.at(i-1)<<" multisims"<<std::endl;
			std::cout<<"File: "<<i<<" has "<<used_multisims.at(i)<<" multisims"<<std::endl;

			if( used_multisims.at(i)!= used_multisims.at(i-1)){
				std::cerr<<"ERROR: number of Multisims for "<<parameter_names.at(0)[0]<<" are different between files in "<<"  "<<parameter_names.at(i)[0]<<std::endl;
				exit(EXIT_FAILURE);
			}
			universes_used = used_multisims.at(0);
		}	
	} else {


		//warning, currently assumes all the same
		std::vector<int> used_multisims(Nfiles,0);
		for(int j = 0;j<Nfiles;j++){
			trees.at(j)->GetEntry(good_event);
			for(std::map<std::string, std::vector<double> >::iterator  it = fWeights.at(j)->begin(); it != fWeights.at(j)->end(); ++it) 
			{
				if( it->first == "bnbcorrection_FluxHist") continue;

				//	if(it->first == "kplus_PrimaryHadronFeynmanScaling")continue;
				//	|| it->first == "kzero_PrimaryHadronSanfordWang" || it->first== "kminus_PrimaryHadronNormalization")continue;

				used_multisims.at(j) += it->second.size();
				std::cout<<"ALL: "<<it->first<<" has "<<it->second.size()<<" multisims in file "<<j<<std::endl;
			}
		}

		for(int i=1; i<Nfiles; i++){
			std::cout<<"File: "<<i-1<<" has "<<used_multisims.at(i-1)<<" multisims"<<std::endl;
			std::cout<<"File: "<<i<<" has "<<used_multisims.at(i)<<" multisims"<<std::endl;
			if( used_multisims.at(i)!= used_multisims.at(i-1)){
				std::cerr<<"ERROR: number of Multisims for "<<parameter_names.at(0)[0]<<" are different between files"<<std::endl;
				exit(EXIT_FAILURE);
			}
		}	

		universes_used = used_multisims.at(0);

	}


	//Ok now we know now many universes we have, initilize all the sbnspecs
	std::cout<<"Initilizing "<<universes_used<<" universes for "<<parameter_names[0][0]<<std::endl;



}




int SBNcovar::formCovarianceMatrix(){
	int num_skipped = 0;
	int num_skipped_kaon = 0;


	TVector3 zaxis(0,0,1);
	int good_event = 2;
	bool cv_filled=false;
	//trees.at(0)->GetEntry(good_event);
	int valid_universe = 0;




		//for(std::map<std::string, std::vector<double> >::iterator  it = fWeights.at(0)->begin(); it != fWeights.at(0)->end(); ++it)
		//if(it->first == "bnbcorrection_FluxHist") continue;

		//		std::cout<<"On MultiSim of "<<it->first<<" which has "<<it->second.size()<<" universes "<<std::endl;	
		//for(auto wei: it->second)
		{
			valid_universe +=1;
			template_spec.Clear();

			for(int j=0;j<Nfiles;j++){

				//	if(j==1) break;
				double pot_factor = pot.at(j)/(pot_scaling.at(j) * (double)nentries.at(j));

				//ENTRY LOOP
				for(int i=0; i< nentries.at(j); i++){
		
					trees.at(j)->GetEntry(i);
		
					if(!eventSelection(j) )continue;	
						
						
					//if(i%5==0)std::cout<<"Event: "<<i<<"/"<<nentries[j]<<" from File: "<<multisim_file[j]<<" on Universe "<<valid_universe+1<<"/"<<universes_used<<std::endl;

					double global_weight = 1;


					//first a check to eliminiate nan/inf in the global bnb correction FluxHist;
					global_weight = fWeights.at(j)->at("bnbcorrection_FluxHist").at(0);

					if(std::isinf(global_weight) || global_weight != global_weight){
						//std::cout<<"Skipping event # "<<i<<" in File "<<multisim_file.at(j)<<" as its either inf/nan: "<<global_weight<<std::endl;
						num_skipped ++;
						continue;
					}
					global_weight = global_weight*pot_factor;

					//Check to see if event is ok of kaon event-bug
					if(parameter_names.at(j)[0] =="ALL" || parameter_names.at(j)[0]=="kplus_PrimaryHadronFeynmanScaling" || parameter_names.at(j)[0] == "kminus_PrimaryHadronNormalization" || parameter_names.at(j)[0]== "kzero_PrimaryHadronSanfordWang"){
						if(fWeights.at(j)->at("kplus_PrimaryHadronFeynmanScaling").size()!=1000 || fWeights.at(j)->at("kminus_PrimaryHadronNormalization").size()!=1000 || fWeights.at(j)->at("kzero_PrimaryHadronSanfordWang").size() != 1000){
							//		//std::cout<<"Skipping event # "<<i<<" in File "<<multisim_file.at(j)<<" as one of the kplus/zero/minus is broke"<<std::endl;
							num_skipped_kaon++;
							continue;
						}

					}

					double wei = fWeights.at(j)->at(parameter_names.at(j)[0]).at(m);
					//std::cout<<"m: "<<m<<"j "<<j<<"i "<<i<<" wei "<<wei<<" "<<fWeights.at(j)->at(parameter_names.at(j)[0]).size()<<" "<<global_weight<<std::endl;
					
	
					if(std::isinf(wei) || wei!= wei){
						std::cout<<"Killing. weight: "<<wei<<" in "<<std::endl; 
						continue;
					}
					if(wei> 1000){
						std::cout<<"ATTENTION: Large weight: "<<wei<<std::endl;
						continue;
					}


					double en = vars_d.at(j)[3];
					template_spec.hist.at(2*j).Fill(en, wei*global_weight);

					double lepAngle = zaxis.Angle(fLepMom.at(j)->Vect());		
					template_spec.hist.at(2*j+1).Fill(cos(lepAngle), wei*global_weight);

					//	if(j==0){ //file 0 electron nue
					//		twoDhists_e.at(m).Fill(en, cos(lepAngle), weights.at(m)  );
					//	}else if(j==1){ //file 2 muon bnb
					//		twoDhists_m.at(m).Fill(en, cos(lepAngle), weights.at(m)  );
					//	}

					if(!cv_filled){
						spec_CV.hist.at(2*j).Fill(en,global_weight);
						spec_CV.hist.at(2*j+1).Fill(cos(lepAngle),global_weight);
						cv_filled = true;
					}
					//	if(j==0){ //file 0 electron nue
					//		CV2D_e.Fill(vars_d.at(j)[3], cos(lepAngle), global_weight  );
					//	}else if(j==1){ //file 2 muon bnb
					//		CV2D_m.Fill(vars_d.at(j)[3], cos(lepAngle), global_weight  );
					//	}


				

				}//end of events
			}//end of files

			template_spec.calcFullVector();
			spec_CV.calcFullVector();	
			std::vector<double> CV = spec_CV.fullVec;



			for(int i=0; i<num_bins_total; i++){
				for(int j=0; j<num_bins_total; j++){

					full_covariance(i,j) += (CV[i]-template_spec.fullVec.at(i))*(CV[j]-template_spec.fullVec.at(j));

					if(full_covariance(i,j)!=full_covariance(i,j)){
						std::cout<<"ERROR: nan : at (i,j):  "<<i<<" "<<j<<" fullcov: "<<full_covariance(i,j)<<" CV: "<<CV[i]<<" "<<CV[j]<<std::endl;
					}

				}
			}





		}//end of weights in this parameter
	} //end of parameters



	for(int i=0; i<num_bins_total; i++){
		for(int j=0; j<num_bins_total; j++){
			full_covariance(i,j) = full_covariance(i,j)/((double)valid_universe);
		}
	}

	for(int i=0; i<num_bins_total; i++){
		for(int j=0; j<num_bins_total; j++){

			frac_covariance(i,j) = full_covariance(i,j)/(spec_CV.fullVec[i]*spec_CV.fullVec[j]) ;
			full_correlation(i,j)= full_covariance(i,j)/(sqrt(full_covariance(i,i))*sqrt(full_covariance(j,j)));
			//	std::cout<<i<<" "<<j<<" "<<full_correlation(i,j)<<" "<<full_covariance(i,j)<<" "<<full_covariance(i,i)<<" "<<full_covariance(j,j)<<" uni-1 "<<universes_used-1.0<<std::endl;
			hist_frac_cov->SetBinContent(i+1,j+1,frac_covariance(i,j));
			hist_full_cor->SetBinContent(i+1,j+1,full_correlation(i,j));
			hist_full_cov->SetBinContent(i+1,j+1,full_covariance(i,j));

		}
	}





	std::cout<<"ATTENTION: Skipped a total of: "<<num_skipped<<" Due to nan/inf bnb weights"<<std::endl;
	std::cout<<"ATTENTION: Skipped a total of: "<<num_skipped_kaon<<" Due to kaon bug"<<std::endl;

	return 0;
	}


	int SBNcovar::writeOut(){

		/************************************************************
		 *			Saving to file				    *
		 * *********************************************************/
		std::string nn = "covariance_matrix_" + parameter_names[0][0]+".root";


		TFile *ftest=new TFile(nn.c_str(),"RECREATE");
		ftest->cd();


		/*
		   TCanvas *cspline =  new TCanvas("Splines");
		   int num_hists = multi_sbnspec.at(0).hist.size();
		   cspline->Divide(num_hists,1);

		   for(int h=0; h<spec_CV.hist.size(); h++){
		   cspline->cd(h+1);
		   spec_CV.hist.at(h).SetLineColor(kBlack);
		   spec_CV.hist.at(h).SetLineWidth(4);
		   spec_CV.hist.at(h).SetTitle( (fullnames[h]+" : "+parameter_names[0][0]).c_str() );
		   spec_CV.hist.at(h).Draw("L SAME hist");
		   }

		   for(int m=0; m< universes_used; m++){
		   for(int h=0; h<multi_sbnspec.at(m).hist.size(); h++){
		   cspline->cd(h+1);
		   TRandom3 * rangen = new TRandom3(0);
		   multi_sbnspec.at(m).hist.at(h).SetLineColor(rangen->Uniform(400,900));

		   multi_sbnspec.at(m).hist.at(h).Draw("L SAME hist");
		   }
		   }

		   for(int h=0; h<spec_CV.hist.size(); h++){
		   cspline->cd(h+1);
		   spec_CV.hist.at(h).SetLineWidth(4);
		   spec_CV.hist.at(h).Draw("L SAME hist");
		   }


		   cspline->Write();
		   std::string ppsp = "splines_"+parameter_names[0][0]+".pdf";

		   cspline->SaveAs(ppsp.c_str());
		 */






		//matricies
		TCanvas *c1 =  new TCanvas("Fractional Covariance Matrix");
		c1->cd();
		gStyle->SetPalette(103); //kSunset
		hist_frac_cov->SetTitle("Fractional Covariance Matrix (sys only)");
		hist_frac_cov->GetYaxis()->SetTitle("E_{#nu}^{truth}");
		hist_frac_cov->GetXaxis()->SetTitle("E_{#nu}^{truth}");
		hist_frac_cov->Draw("COLZ");
		c1->Write();

		TCanvas *c2 =  new TCanvas("Correlation Matrix");
		c2->cd();

		hist_full_cor->SetTitle("Correlation Matrix (sys only)");
		hist_full_cor->GetYaxis()->SetTitle("E_{#nu}^{truth}");
		hist_full_cor->GetXaxis()->SetTitle("E_{#nu}^{truth}");
		hist_full_cor->Draw("COLZ");
		c2->Write();	

		TCanvas *c3 =  new TCanvas("Covariance Matrix");
		c3->cd();

		hist_full_cov->SetTitle("Covariance Matrix (sys only)");
		hist_full_cov->GetYaxis()->SetTitle("E_{#nu}^{truth}");
		hist_full_cov->GetXaxis()->SetTitle("E_{#nu}^{truth}");
		hist_full_cov->Draw("COLZ");
		c3->Write();

		std::string pp = "Fractional Covarariance and Correlation: "+parameter_names[0][0];
		TCanvas *cboth = new TCanvas(pp.c_str());
		cboth->SetCanvasSize(1800,600);

		hist_frac_cov->SetTitle( ("Fractional Covariance: "+ parameter_names[0][0]).c_str());
		hist_full_cor->SetTitle( ("Correlation: "+ parameter_names[0][0]).c_str());
		cboth->Divide(2,1);

		//cboth->SetFixedAspectRatio();
		cboth->cd(1);
		//	cboth->SetBorderSize(20);

		hist_frac_cov->Draw("COLZ");

		//cboth->SetRightMargin(0.30);
		cboth->cd(2);


		hist_full_cor->Draw("COLZ");
		//cboth->SetRightMargin(0.30);
		//cboth->Update();
		cboth->Write();

		hist_full_cov->Write();
		hist_frac_cov->Write();
		hist_full_cor->Write();

		std::string ppdf = "covar_plots_"+parameter_names[0][0]+".pdf";
		cboth->SaveAs(ppdf.c_str());


		frac_covariance.Write();
		full_covariance.Write();
		full_correlation.Write();

		ftest->Close();

		spec_CV.writeOut("CV.root");


		/************************************************************
		 *		Quality Testing Suite			    *
		 * *********************************************************/


		if(full_covariance.IsSymmetric()){
			std::cout<<"Generated covariance matrix is symmetric"<<std::endl;
		}else{
			std::cerr<<"ERROR: SBNcovar::formCovarianceMatrix, result is not symmetric!"<<std::endl;
			exit(EXIT_FAILURE);
		}


		//if a matrix is (a) real and (b) symmetric (checked above) then to prove positive semi-definite, we just need to check eigenvalues and >=0;
		TMatrixDEigen eigen (full_covariance);
		TVectorD eigen_values = eigen.GetEigenValuesRe();


		for(int i=0; i< eigen_values.GetNoElements(); i++){
			if(eigen_values(i)<0){
				is_small_negative_eigenvalue = true;
				if(fabs(eigen_values(i))> tolerence_positivesemi ){
					std::cerr<<"ERROR: SBNcovar::formCovarianceMatrix, contains (at least one)  negative eigenvalue: "<<eigen_values(i)<<std::endl;
					exit(EXIT_FAILURE);
				}
			}
		}


		if(is_small_negative_eigenvalue){	
			std::cout<<"Generated covariance matrix is (allmost) positive semi-definite. It did contain small negative values of absolute value <= :"<<tolerence_positivesemi<<std::endl;
		}else{
			std::cout<<"Generated covariance matrix is also positive semi-definite."<<std::endl;
		}


		return 0;
	}







	/***************************************************************
	 *		Some virtual functions for selection and histogram filling
	 * ************************************************************/

	bool SBNcovar::eventSelection(int which_file){
		//from here have access to vars_i  and vars_d  to make a selection

		bool ans = false;
		if(which_file==0){
			if(fabs(vars_i.at(which_file)[3]) == 12  ){
				ans = true;
			}
		} else if (which_file==1){
			if(fabs(vars_i.at(which_file)[3]) == 14  ){
				ans = true;
			}


		}

		return ans;
	}

	int SBNcovar::fillHistograms(int file, int uni, double wei){
		//Fill the histograms
		//
		/*	TRandom3 rangen(0);
			double sigma = 0;
			if(file==0){
			sigma=;
			}else if(file==1){
			sigma=;
			}	
			double en = rangen.Gaus( vars_d.at(file), sigma );
		 */	
		double en = vars_d.at(file)[3];
		double cosTh = cos(vars_d.at(file)[2] );
		//this is one that works
		//multi_sbnspec.at(uni).hist.at(file).Fill(en, wei);


		//multi_sbnspec.at(uni).hist.at(file).Fill(en, wei);
		//multi_sbnspec.at(uni).hist.at(1).Fill(cosTh, wei);


		return 0;
	}
